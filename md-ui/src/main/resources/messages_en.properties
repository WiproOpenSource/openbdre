common.page.title_bdre_1=Data Discovery Platform
common.page.title_bdre_2=BDRE | Data Discovery Platform


login.page.title_bdre=Big Data Ready Enterprise
login.page.footer_bdre=
login.page.sign_button=Sign in
login.page.error=Error:
login.page.info=Info:
login.page.username=Username
login.page.password=Password
login.page.forgot_password=Forgot Password?
login.page.title=Login Page

welcome.page.bdre_description=Our product attempts to make big data technology simpler by optimizing and integrating various big data solutions and providing them under one integrated package, Big Data Ready Enterprises, or BDRE. BDRE is a Bigdata/Hadoop unified framework developed with the goal of drastically minimizing development time.

welcome.page.canvas_error=Your browser does not support the HTML5 canvas tag.
welcome.page.head_var="Metadata Management", "Data Integrity", "Batch Lineage", "Data Quality", "Automation", "Data Extraction", "Run Control", "Test Data Generation", "Dependency Management", "Data Loading", "Visualization", "Analytics"
welcome.page.text_var="Automation1", "Automation2", "Automation3", "Automation4", "Automation1", "", "", "", "", "", "", ""
welcome.page.desc_var="End-to-end process and governance framework.","End-to-end data integrity protection by error checking and validation at necessary steps.","Detailed end-to-end batch lineage information.","Makes data reliable for making business decisions.","Enables business streamlining.Drastically reduces errors and prevents jobs from falling through the cracks.","Extraction of data to retrieve relevant information from data sources.","Monitoring and controlling the process execution.","Automated bulk test data generation.","Process and workflow dependencies for auditing.","Fast dataset loading.","Graphical representaion of workflows and dependencies.","Analysis of process run execution time."
welcome.page.tail_var="", "", "", "", ""
welcome.page.taillinks_var="url1", "url2", "url3", "url4", "url1", "url2", "url3", "url4"
welcome.page.imgs_var="../css/images/metadata.jpg", "../css/images/dataintegrity.jpg", "../css/images/datalineage.jpg", "../css/images/dataquality.jpg", "../css/images/automation.jpg", "../css/images/extraction.jpg", "../css/images/runcontrol.jpg", "../css/images/datagen.jpg", "../css/images/dependancy.jpg", "../css/images/loading.jpg", "../css/images/visualization.jpg", "../css/images/analytic.jpg"

403.page.error_desciption=You do not have permission to access this page!
403.page.http_error= Status 403 - Access is denied

filemonitor.page.panel_heading_file_monitoring_creation = File Monitoring Creating Process
filemonitor.page.property_form_field_dir_name = File Monitoring Dir Name
filemonitor.page.property_form_field_file_pattern = File Pattern
filemonitor.page.property_form_field_srcfile_action = Copied Source File Action
filemonitor.page.property_form_field_hdfs_upload_dir = HDFS Upload Dir Name
filemonitor.page.property_form_field_polling_interval = Polling Interval(in milliseconds)
filemonitor.page.property_form_field_process_name = Process Name:
filemonitor.page.property_form_field_process_desc = Process Description:
filemonitor.page.property_form_field_bus_domain_id = Bus Domain Id:
filemonitor.page.success_header = Job Created Successfully
filemonitor.page.property_form_field_dir_name_placeholder=File Monitoring Dir Name
filemonitor.page.property_form_field_file_pattern_placeholder=File Pattern Monitored
filemonitor.page.property_form_field_hdfs_upload_dir_placeholder=HDFS Upload Directory Name
filemonitor.page.property_form_field_polling_interval_placeholder=time in milliseconds
filemonitor.page.property_form_field_process_name_placeholder=Enter Process Name
filemonitor.page.property_form_field_process_desc_placeholder=Enter Process Description


dqprocess.page.panel_heading = Setup DQ Job
dqprocess.page.form_rules_username = Rules Username
dqprocess.page.form_rules_psswd = Rules Password
dqprocess.page.form_rules_pckgs = Rules Packages
dqprocess.page.form_file_delimiter = File Delimiter
dqprocess.page.form_threshold_min_val = Min pass threshold %
dqprocess.page.form_bus_domainID = Application
dqprocess.page.form_recoverability = Can Recover
dqprocess.page.form_enq_id = Enq Id
dqprocess.page.form_process_name = Process Name
dqprocess.page.form_desc = Description


deploy.page.title = DDP | Deployment
deploy.page.heading = DDP Job Deployment
deploy.page.progress_label = Loading...

dataload.page.alert_info_outer_heading = Application requires process details to create process entries in metadata
dataload.page.h3_div = Provide Process Details
dataload.page.form_left_procname = Process Name:
dataload.page.form_left_procdesc = Process Description:
dataload.page.form_left_bus_domain_id = Bus Domain Id:
dataload.page.form_right_enqueing_id = Enqueing Id:
dataload.page.h3_div_2 = Raw Table Details
dataload.page.alert_info_form = Type of file you want to load in hive
dataload.page.raw_db_name = Raw DB Name:
dataload.page.file_format = File Format:
dataload.page.raw_table_props = Raw Table Properties
dataload.page.formats = Serde, OutPut and Input Format
dataload.page.provide_props = Provide Serde Properties
dataload.page.how_to = How To:
dataload.page.enter_props = Enter Serde Properties key and value
dataload.page.provide_table_props = Provide Table Properties
dataload.page.enter_table_key_value = Enter Table Properties key and value
dataload.page.base_table_name = Base Table Name AND DB
dataload.page.alert_info_base_table = Application requires process details to create process entries in metadata
dataload.page.base_db_name = BASE DB Name:
dataload.page.base_table_name_single = Base Table Name:
dataload.page.base_table_details = Base Table Details
dataload.page.confirm = Confirm
dataload.page.create_jobs = Create Jobs
dataload.page.form_left_procname_placeholder=Enter Process Name
dataload.page.form_left_procdesc_placeholder=Enter Process Description
dataload.page.form_right_enqueing_id_placeholder=Enter Enqueing Process Id
dataload.page.raw_db_name_placeholder=Enter RAW DB Name
dataload.page.serde_key_placeholder=Serde Key"
dataload.page.serde_property_placeholder=Serde Property
dataload.page.table_property_placeholder=Table Property
dataload.page.table_prop_key_placeholder=Table Prop Key
dataload.page.base_db_name_placeholder=Enter BASE DB Name
dataload.page.enter_base_table_name_placeholder =Enter BASE TABLE NAME



appstore.page.p_confirmation = Are you sure you want to install this app?
appstore.page.install = Install
appstore.page.install_progress = Installing Please wait....
appstore.page.install_complete = Process installed Successfully
appstore.page.installtall_error = Error in app installation.

adq.page.export_to_app_store = This will export the application to appstore
adq.page.export_reject = This will reject exporting of the application to appstore
adq.page.process_initiation_status = Process Started Successfully

dataimportwizard.page.db = Database
dataimportwizard.page.db_url = Database URL
dataimportwizard.page.db_user = Database User
dataimportwizard.page.db_psswd = Database Password
dataimportwizard.page.db_driver = Database Driver
dataimportwizard.page.schema= Schema
dataimportwizard.page.table_and_cols = Table and Columns
dataimportwizard.page.hive_db = RAW Hive DB
dataimportwizard.page.hive_base = BASE Hive DB
dataimportwizard.page.submission = Submission
dataimportwizard.page.business_domain_id = Business Domain Id
dataimportwizard.page.process_name = Process Name
dataimportwizard.page.process_desc = Process Description
dataimportwizard.page.p_section = Pressing 'Create Job' will make the system build following job workflows
dataimportwizard.page.span_a = Data Extraction Workflows to ingest the data from selected RDBMS tables to Hadoop
dataimportwizard.page.span_b = A Data Loading Workflow to load the ingested data into Hive table in ORC format.
dataimportwizard.page.div_alert = Create Jobs will be connected automatically so upon completion of Data Extraction Workflow, Data Loading Workflow is enqueued automatically.
dataimportwizard.page.confirm = Confirm

appexport.page.pannel_heading = Download Zip or Export to App Store
appexport.page.download = Download Zip
appexport.page.export_to_appstore = Export to AppStore
appexport.page.application_name = Application Name
appexport.page.select_business_domain = Select Business Domain
appexport.page.upload_app_img = Upload App Image
appexport.page.appname_placeholder=Application Name
appexport.page.upload_app_img_placeholder=Upload App Image


batchlineagebyinstanceexec.page.instance_exec_id = Instance Exec Id:
batchlineage.page.placeholder=Enter a batchid

content.page.app_abbrevation = Data Discovery Platform

crawler.page.alert_info_outer = Application requires crawling details to be entered
crawler.page.crawler_details = Crawler Details
crawler.page.urls_to_crawl = Urls to crawl:
crawler.page.regex_search_pattern = Regex Pattern to search:
crawler.page.regex_dont_search_pattern = Regex Pattern not to search:
crawler.page.politeness_delay = Politeness Delay:
crawler.page.max_crawl_depth = Max depth of crawling:
crawler.page.max_pages_to_fetch = Max pages to fetch:
crawler.page.include_binary_content= Include binary content:
crawler.page.resumable_crawling = Resumable crawling:
crawler.page.user_agent_string = User agent string:
crawler.page.num_of_mappers = Number of mappers:
crawler.page.h3_div= Proxy Details
crawler.page.alert_info_2 = Application requires proxy details (if you are using proxy to access internet)
crawler.page.proxy_port = Proxy-port:
crawler.page.proxy_host = Proxy-host:
crawler.page.proxy_user_name = Proxy-username:
crawler.page.proxy_password = Proxy-password:
crawler.page.process_details = Process Details
crawler.page.alert_info_3 = Application requires process details to create process entries in metadata
crawler.page.proc_name = Process Name:
crawler.page.proc_desc = Process Description:
crawler.page.hdfs_output_path = HDFS Output Path:
crawler.page.bus_domain_id = Bus Domain Id:
crawler.page.confirm = Confirm
crawler.page.create_crawler = Create Crawler
crawler.page.urls_to_crawl_placeholder =Enter Urls to crawl (comma seperated)
crawler.page.regex_search_pattern_placeholder=Enter Regex Pattern to search
crawler.page.regex_dont_search_pattern_placeholder =Enter Regex Pattern not to search
crawler.page.politeness_delay_placeholder=Enter Politeness Delay
crawler.page.max_crawl_depth_placeholder=Enter max depth of crawling
crawler.page.max_pages_to_fetch_placeholder=Enter max pages to fetch
crawler.page.resumable_crawling_placeholder=Crawling should be resumable?
crawler.page.user_agent_string_placeholder=Enter user agent string
crawler.page.num_of_mappers_placeholder=Enter number of mappers
crawler.page.proxy_port_placeholder=Enter proxy-port
crawler.page.proxy_host_placeholder=Enter proxy-host e.g.:proxy.domain.com
crawler.page.proxy_user_name_placeholder=Enter proxy-username
crawler.page.proxy_password_placeholder=Enter proxy-password
crawler.page.proc_name_placeholder=Enter Process Name
crawler.page.proc_desc_placeholder=Enter Process Description
crawler.page.hdfs_output_path_placeholder=Enter the absolute Output Path

columnlineage.page.placeholder=Enter a process id


datagen.page.how_to = How To:
datagen.page.b_datatype_format = For Date type use format:
datagen.page.b_span = 2012-09-09,2013-09-08,yyyy-MM-dd
datagen.page.b_regex_pattern = For Regex pattern use format:
datagen.page.b_regex_pattern_span = string1|string2
datagen.page.number_format = For number type use format:
datagen.page.number_format_span = min Value,max Value
datagen.page.column_type = Enter the Column Name : Column Type as:
datagen.page.column_type_span = name:type for e.g.:- account_type:string or open_date:date
datagen.page.data_types = Data Type Details
datagen.page.table_types = Table Type Details
datagen.page.alert_info = Application requires Table type details to
datagen.page.number_of_records = Number of records:
datagen.page.number_of_splits = Number of Splits:
datagen.page.field_separator = Field Separator:
datagen.page.table_name = Table Name:
datagen.page.proc_details = Process Details
datagen.page.alert-info_2 = Application requires process details to create process entries in metadata
datagen.page.proc_name = Process Name:
datagen.page.proc_desc = Process Description:
datagen.page.hdfs_op_path = HDFS Output Path:
datagen.page.bus_domain_id = Bus Domain Id:
datagen.page.confirm = Confirm
datagen.page.hdfs_op_path_placeholder=Enter the absolute Output Path
datagen.page.proc_desc_placeholder=Enter Process Description
datagen.page.proc_name_placeholder=Enter Process Name
datagen.page.table_name_placeholder=Table Name
datagen.page.field_separator_placeholder=Field Separator
datagen.page.number_of_splits_placeholder=Enter Number of Splits
datagen.page.number_of_records_placeholder=Enter Number of records generation
datagen.page.colname_type_placeholder=Column Name : Column Type
datagen.page.generator_argument_placeholder=Generator Argument

wfdesigner.page.panel_heading=Information
wfdesigner.page.panel_body=Click on the node to see node properties
wfdesigner.page.process_details=Process Details
wfdesigner.page.id=Id:
wfdesigner.page.type=Type:
wfdesigner.page.name=Name:
wfdesigner.page.description=Description:
wfdesigner.page.update_process_details=Update Process Details
wfdesigner.page.jar_configuration=Jar Configuration
wfdesigner.page.select_file=Select file :
wfdesigner.page.upload_jar=Upload jar
wfdesigner.page.propkey_name=Name:
wfdesigner.page.propkey_value=Value:
wfdesigner.page.select_hql_file=Select HQL file :
wfdesigner.page.select_r_file=Select R file :
wfdesigner.page.select_shell_script=Select shell script :
wfdesigner.page.add_files=Add files:
wfdesigner.page.select_pig_script=Select pig script :
wfdesigner.page.select_spark_jar=Select spark jar:
wfdesigner.page.create_new_workflow=Create New Workflow
wfdesigner.page.process_name=Process Name
wfdesigner.page.domain=Domain
wfdesigner.page.workflow_type=Workflow Type
wfdesigner.page.create_process=Create Process
wfdesigner.page.propval_value_placeholder=Enter value
wfdesigner.page.propkey_name_placeholder=Enter name
wfdesigner.page.search_property_placeholder=Search Property


flumepropertieswizard.page.source_type_alert=Application requires source type which depends on how you are getting your data
flumepropertieswizard.page.source_type=Select Source Type
flumepropertieswizard.page.required_source_properties=Required Source Properties
flumepropertieswizard.page.source_type_configuration_properties_alert=Form contains required configuration properties related with your selected source type.
flumepropertieswizard.page.advanced_source_properties=Advanced Source Properties
flumepropertieswizard.page.source_type_advanced_configuration_properties_alert=Table contains advanced configuration properties related with your selected source type. Use edit and delete button to change or delete properties.
flumepropertieswizard.page.select_channel_type=Select Channel Type
flumepropertieswizard.page.channel_type_alert=Application requires channel type which depends on how you want to transfer your data from source to sink
flumepropertieswizard.page.required_channel_properties=Required Channel Properties
flumepropertieswizard.page.channel_type_configuration_properies_alert=Form contains required configuration properties related with your selected channel type.
flumepropertieswizard.page.advanced_channel_properties=Advanced Channel Properties
flumepropertieswizard.page.advanced_channel_type_configuration_properities_alert=Table contains advanced configuration properties related with your selected channel type. Use edit and delete button to change or delete properties.
flumepropertieswizard.page.select_sink_type=Select Sink Type
flumepropertieswizard.page.sink_type_alert=Application requires sink type which depends on where you want to dump your data
flumepropertieswizard.page.required_sink_properties=Required Sink Properties
flumepropertieswizard.page.sink_type_configuration_properies_alert=Form contains required configuration properties related with your selected sink type.
flumepropertieswizard.page.advanced_sink_properties=Advanced Sink Properties
flumepropertieswizard.page.sink_type_advanced_configuration_properies_alert=Table contains advanced configuration properties related with your selected sink type. Use edit and delete button to change or delete properties.
flumepropertieswizard.page.process_details=Process Details
flumepropertieswizard.page.process_details_alert=Application requires process details to create process entries in metadata
flumepropertieswizard.page.process_name=Process Name:
flumepropertieswizard.page.process_description=Process Description:
flumepropertieswizard.page.bus_domain_id=Bus Domain Id:
flumepropertieswizard.page.confirm=Confirm
flumepropertieswizard.page.process_description_palceholder=Enter Process Description
flumepropertieswizard.page.process_name_placeholder=Enter Process Name

lineage.page.parent_process_id_placeholder=Enter a Parent ProcessId

processgraph.page.x_axis=X axis : Sample time(from current) in hours
processgraph.page.y_axis=Y axis : Duration of the execution in section

processimportwizard.page.zip_file_upload=Zip File Upload
processimportwizard.page.imported_details=Imported Details

processlog.page.filter_by_processid_placeholder=Filter by processid

processtemplate.page.filter_by_processtemplateid_placeholder=Filter by processtemplateid
processtemplate.page.filter_by_edit_process_placeholder=This will edit all the relevant process entries in the process table as per this configuration. Do you want to proceed?
processtemplate.page.filter_by_new_process_placeholder=This will create a new process in the process table with the same configuration as this. Do you want to proceed?
processtemplate.page.process_name=Process Name
processtemplate.page.process_description=Process Description

settings.page.configuration_alert=Application requires configuration type which is needed for setting or seeing configuration value

sla.page.sub_process_execution_time_graph=Execution Time graph of sub processes of process
sla.page.subprocess_ids=SubprocessIDs -->

tablecolumnlineage.page.table_column_lineage_bdre=Table Column Lineage | DDP
tablecolumnlineage.page.process_not_found=Process Not Found
tablecolumnlineage.page.column_name=Column Name is:
tablecolumnlineage.page.table_name=Table Name is:
tablecolumnlineage.page.table_column_lineage=Table Column Lineage


uploadertest.page.file_alert=Please delete this JSP file when the feature is implemented in WFD. This is just a sample.
uploadertest.page.select_file=Select a file:

process.page.pid_placeholder=""
