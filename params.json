{"name":"Bigdata Ready Enterprise","tagline":"Making Bigdata Easy For Enterprise","body":"# Bigdata Ready Enterprise Open Source Software\r\n\r\n## Table of Contents\r\n\r\n[License](#license)\r\n[Objective](#objective)\r\n\r\n[Features](#features)\r\n\r\n[Architecture](#architecture)\r\n\r\n[Installation](#installation)\r\n\r\n[Data Ingestion](#data-ingestion)\r\n\r\n[Workflow Builder](#workflow-builder)\r\n\r\n[Bulk Data Manufacturing](#bulk-data-manufacturing)\r\n\r\n[Web Crawler](#web-crawler)\r\n\r\n[Operational Metadata Management](#operational-metadata-management)\r\n\r\n[How To Contribute](#how-to-contribute)\r\n***\r\n\r\n# License\r\nReleased under Apache Public License 2.0. You can get a copy of the license at http://www.apache.org/licenses/LICENSE-2.0.\r\n# Objective\r\nBig Data Ready Enterprise(BDRE) makes big data technology adoption simpler by optimizing and integrating various big data solutions and providing them under one integrated package. BDRE provides a uniﬁed framework for a Hadoop implementation that can drastically minimize development time and fast track the Hadoop implementation. It comprises a reusable framework that can be customized as per the enterprise ecosystem. The components are loosely integrated and can be de-coupled or replaced easily with alternatives.\r\n \r\nThe primary goal of BDRE is to accelerate Bigdata implementations by supplying the essential frameworks that are most likely to be written from scratch. It can drastically reduce effort by eliminating hundreds of man hours in operational framework development. Big Data implementations however, require specialized skills, signiﬁcant development effort on data loading, semantic processing, DQ, code deployment across environments etc.\r\n\r\n# Features\r\n\r\n- Operational Metadata Management\r\n - Registry of all workflow processes/templates\r\n - Parameters/configuration(key/value) for processes\r\n - Dependency information (upstream/downstream)\r\n - Batch management/tracking. Batch concept in BDRE is for tracking the data flow between workflow processes.\r\n - Run control (for delta processing/dependency check)\r\n - Execution status for jobs(dynamic metadata - with step level granularity)\r\n - File registry - can be used to register e.g. ingested files or a raw file as an output of an upstream.\r\n - Execution statistics logging (key/value)\r\n - Executed hive queries and data lineage information.\r\n - Java APIs that integrates with Big Data with non-Big Data applications alike.\r\n - Job monitoring and proactive/reactive alerting\r\n- Data ingestion framework\r\n - Tabular data from RDBMS\r\n - Streaming data from 16 types of sources (including logs, message queues and Twitter)\r\n - Arbitrary file ingestion by directory monitoring\r\n- Web Crawler\r\n- Distributed Data Manufacturing framework\r\n - Generate billions of records based on patterns and ranges\r\n- Semantic Layer Building Framework\r\n - Build the semantic layer using visual workflow creator using the data you ingested.\r\n - Supports Hive, Pig, MapReduce, Spark, R etc.\r\n - Generates Oozie workflows\r\n- Data Quality Framework\r\n - Validates your data using your rules in a distributed way\r\n - Integrated with Drools rule engine\r\n- HTML5 User Interface\r\n - Create ingestion, data generation, Crawler jobs or create Oozie workflows graphically without writing any code\r\n - One click deploy and execute jobs without SSH into the edge node.\r\n\r\n# Architecture\r\n\r\n![image](http://wiproopensourcepractice.github.io/openbdre/bdreimages/architecture.PNG)\r\n\r\n# Installation\r\n\r\n## Overview\r\n\r\nThis section will help you build BDRE from source. Audience for this document are developers and architects who want be part of BDRE framework development or may just want to evaluate it.\r\n\r\n### General Prerequisite\r\n\r\nFor testing/development purpose and to save time, use the fully loaded Hadoop VMs from Cloudera or Hortonworks because all the required software are typically installed and configured.\r\n\r\n- A Hadoop Cluster\r\n - In this section we are using *Hortonworks Sandbox 2.2.0*\r\n- Git 1.9 and up\r\n- Maven 3 and up\r\n- Oracle JDK 7(and up)\r\n- BDRE is shipped with an embedded database which is okay for running the UI and evaluating and testing jobs in a single node cluster.\r\nFor production use BDRE currently supports following production scale databases.)\r\n  - MySQL Server 5.1 and up\r\n  - Oracle 11g Server or better\r\n  - PostgreSQL\r\n- Google Chrome browser\r\n\r\nYou should be able to do the same in Mac or Windows but note that setting up a Hadoop cluster might be tricky in Windows and might require more involvement. However to deploy and run the jobs we recommend a Linux system. BDRE is typically installed in Hadoop edge node in a multi-node cluster.\r\n\r\n## Preparation\r\n\r\n* Download and install VirtualBox from https://www.virtualbox.org/\r\n* Download and install Hortonworks Sandbox 2.2 Virtual Box image from http://hortonworks.com/products/releases/hdp-2-2/#install\r\n* Setup a 'Host-Only Adapter' for network to enable communication between Host and Guest OS.\r\n* Now ssh into the sandbox using *root@VM_IP* (password hadoop)\r\n    - The VM_IP is usually something between 192.168.56.101 - 192.168.56.109\r\n\r\n* Now create *openbdre* user account.\r\n\r\n    ```shell\r\n    [root@sandbox ~]# adduser -m -s /bin/bash openbdre\r\n    [root@sandbox ~]# passwd openbdre\r\n    Changing password for user openbdre.\r\n    New password:\r\n    Retype new password:\r\n    passwd: all authentication tokens updated successfully.\r\n    ```\r\n* As root edit /etc/sudoers and allow openbdre to perform `sudo`. Below will do it\r\n\r\n    ```shell\r\n    echo \"openbdre ALL=(ALL) NOPASSWD:ALL\" >> /etc/sudoers\r\n    ```\r\n\r\n* Login to the HDP Sandbox with the newly created openbdre user. You can perform a **su openbdre** to switch to this account. Please make sure you are not root user beyond this point.\r\n\r\n    ```shell\r\n    [root@sandbox ~]# su openbdre\r\n    [openbdre@sandbox root]$ cd ~\r\n    [openbdre@sandbox ~]$\r\n    ```\r\n\r\n* Download Maven from a mirror, unpack and add to the PATH.\r\n\r\n    ```shell\r\n    [openbdre@sandbox ~]# wget http://www.us.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip\r\n    [openbdre@sandbox ~]# unzip apache-maven-3.3.9-bin.zip\r\n    [openbdre@sandbox ~]# export PATH=$PATH:/home/openbdre/apache-maven-3.3.9/bin\r\n    ```\r\n\r\n## Building BDRE from source\r\n\r\n1. Obtain the source code\r\n * cd to the home directory of openbdre.\r\n\r\n    ```shell\r\n    [openbdre@sandbox ~]# cd ~\r\n    ```\r\n\r\n * Pull BDRE source from this git repository. To find out your repository link navigate to the repository in this website and copy the https repo URL.\r\n\r\n    ```shell\r\n    [openbdre@sandbox ~]# git clone https://github.com/WiproOpenSourcePractice/openbdre.git\r\n    ```\r\n\r\n * cd to the cloned source dir (so you can be in /home/openbdre/openbdre)\r\n\r\n    ```shell\r\n    [openbdre@sandbox ~]# cd openbdre\r\n    ```\r\n\r\n2. Database Setup\r\n    * Execute the dbsetup.sh script without any parameters as shown below. In this example, we are going to use MySQL as BDRE backend as it's already available in the HDP Sandbox. If you would like to use another database please select it accordingly.\r\n\r\n    ```shell\r\n    [openbdre@sandbox ~]# sh dbsetup.sh\r\n    ```\r\n\r\n    ```shell\r\n    [openbdre@sandbox openbdre]$ sh dbsetup.sh⏎\r\n    Supported DB\r\n    1) Embedded (Default - Good for running BDRE user interface only. )\r\n    2) Oracle\r\n    3) MySQL\r\n    4) PostgreSQL\r\n\r\n    Select Database Type(Enter 1, 2, 3 , 4 or leave empty and press empty to select the default DB):3⏎\r\n\r\n    Enter DB username (Type username or leave it blank for default 'root'):⏎\r\n    Enter DB password (Type password or leave it blank for default '<blank>'):⏎\r\n    Enter DB hostname (Type db hostname or leave it blank for default 'localhost'):⏎\r\n    Enter DB port (Type db port or leave it blank for default '3306'):⏎\r\n    Enter DB name (Type db name or leave it blank for default 'bdre'):⏎\r\n    Enter DB schema (Type schema or leave it blank for default 'bdre'):⏎\r\n    Please confirm:\r\n\r\n    Database Type: mysql\r\n    JDBC Driver Class: com.mysql.jdbc.Driver\r\n    JDBC Connection URL: jdbc:mysql://localhost:3306/bdre\r\n    Database Username: root\r\n    Database Password:\r\n    Hibernate Dialect: org.hibernate.dialect.MySQLDialect\r\n    Database Schema: bdre\r\n    Are those correct? (type y or n - default y):y⏎\r\n    Database configuration written to ./md-dao/src/main/resources/db.properties\r\n    Will create DB and tables\r\n    Tables created successfully in MySQL bdre DB\r\n    ```\r\n\r\n3. Building\r\n * Now build BDRE using (note BDRE may not compile if the **settings.xml** is not passed from the command line so be sure to use the *-s* option. When building for the first time, it might take a while as maven resolves and downloads the jar libraries from different repositories.\r\n\r\n    ```shell\r\n    mvn -s settings.xml clean install -P hdp22\r\n    ```\r\n * *Note:* Selecting hdp22 will compile BDRE with HDP 2.2 libraries and automatically configure BDRE with Hortonworks Sandbox 2.2.0. Similarly one should be able to build this using -P cdh52 which will configure BDRE for CDH 5.2 QuickStart VM. During building it'll pick up the environment specific configurations from <source root>/databases/setup/profile.*hdp22*.properties.\r\n\r\n    Content of databases/setup/profile.hdp22.properties\r\n ```properties\r\n    bdre_user_name=openbdre\r\n    name_node_hostname=sandbox.hortonworks.com\r\n    name_node_port=8020\r\n    job_tracker_port=8050\r\n    flume_path=/usr/hdp/current/flume-server\r\n    oozie_host=sandbox.hortonworks.com\r\n    oozie_port=11000\r\n    thrift_hostname=sandbox.hortonworks.com\r\n    hive_server_hostname=sandbox.hortonworks.com\r\n    drools_hostname=sandbox.hortonworks.com\r\n    hive_jdbc_user=openbdre\r\n    hive_jdbc_password=openbdre\r\n ```\r\n\r\n    ```shell\r\n    $ mvn -s settings.xml clean install -P hdp22\r\n    [INFO] Scanning for projects...\r\n    [INFO] ------------------------------------------------------------------------\r\n    [INFO] Reactor Build Order:\r\n        .......blah blah.........\r\n        .......blah blah.........\r\n    [INFO] ------------------------------------------------------------------------\r\n    [INFO] BUILD SUCCESS\r\n    [INFO] ------------------------------------------------------------------------\r\n    [INFO] Total time: 3:39.479s\r\n    [INFO] Finished at: Wed Dec 30 01:50:02 PST 2015\r\n    [INFO] Final Memory: 127M/2296M\r\n    [INFO] ------------------------------------------------------------------------\r\n    ```\r\n\r\n4. Installing BDRE\r\n * After building BDRE successfully run\r\n\r\n    ```shell\r\n    sh install-scripts.sh local\r\n    ```\r\n * It'll install the BDRE scripts and artifacts in /home/openbdre/bdre\r\n\r\n### Using BDRE\r\n\r\n* After a successful build, start the BDRE UI service\r\n\r\n```shell\r\n sudo service bdre start\r\n```\r\n* Start Oozie as the Oozie user incase Oozie isn't already started. ```ps -ef | grep -i oozie``` will help determine status of Oozie.\r\n\r\n    ```shell\r\n    su - oozie -c \"/usr/hdp/current/oozie-server/bin/oozie-start.sh\"\r\n    ps -ef | grep -i oozie\r\n    ```\r\n* Use *Google Chrome browser* from the host machine and open *http://VM_IP:28850/mdui/pages/content.page*\r\n* Login using admin/zaq1xsw2\r\n\r\n### Creating, Deploying and Running a Test Job\r\n\r\n* Create a RDBMS data import job from *Job Setup From Template > Import from RDBMS*\r\n* Change the JDBC URL/credentials to your local MySQL DB that contains some data.\r\n* Click *Test Connection*\r\n* Expand and select 1 table (be sure to expand the tables before selecting).\r\n* Create the jobs and see the pipeline.\r\n* Click *XML*, *Diagram* etc. and check the generated Oozie workflow XML and diagram.\r\n* Search for 'Process' in the search window and open the 'Process' page\r\n* Click deploy button on process page corresponding to the process you want to deploy. (Deploy button will show status regarding deployment of process, when you hover over the button.)\r\n* Wait for 2 minutes and the deployment will be completed by then.\r\n* After the deployment is complete and in UI the status for the process is deployed (turns green).\r\n* Click the execution button to execute the *Import job*.\r\n* Check the process in Oozie console *http://VM_IP:11000/oozie*\r\n* When the import job is complete start the *data load job*.\r\n\r\n# Data Ingestion\r\n\r\n## RDBMS Data Ingestion\r\n\r\n<a href=\"http://www.youtube.com/watch?v=JcbYU7oEmxc\" target=\"_blank\"><img src=\"http://wiproopensourcepractice.github.io/openbdre/bdreimages/rdbms.PNG\" \r\nalt=\"BDRE RDBMS data ingestion demo video\" width=\"240\" height=\"180\" border=\"10\" /></a>\r\n\r\n\r\n## Streaming Data Ingestion\r\n\r\n<a href=\"http://www.youtube.com/watch?v=1yqoAVENrjo\" target=\"_blank\"><img src=\"http://wiproopensourcepractice.github.io/openbdre/bdreimages/twitter.PNG\" \r\nalt=\"BDRE Twitter Ingestion demo video\" width=\"240\" height=\"180\" border=\"10\" /></a>\r\n\r\n\r\n## Directory Monitoring and File Ingestion\r\n\r\n<a href=\"http://www.youtube.com/watch?v=IhDMYase1fU\" target=\"_blank\"><img src=\"http://wiproopensourcepractice.github.io/openbdre/bdreimages/filemon.PNG\" \r\nalt=\"BDRE File ingestion demo video\" width=\"240\" height=\"180\" border=\"10\" /></a>\r\n\r\n# Workflow Builder\r\n\r\n<a href=\"http://www.youtube.com/watch?v=PG6Qvg-pKO0\" target=\"_blank\"><img src=\"http://wiproopensourcepractice.github.io/openbdre/bdreimages/wfd.PNG\" \r\nalt=\"BDRE Workflow Designer demo video\" width=\"240\" height=\"180\" border=\"10\" /></a>\r\n\r\n# Bulk Data Manufacturing\r\nDemo video TBD\r\n# Web Crawler\r\n\r\n<a href=\"http://www.youtube.com/watch?v=0b6dWGxin4Y\" target=\"_blank\"><img src=\"http://wiproopensourcepractice.github.io/openbdre/bdreimages/crawler.PNG\" \r\nalt=\"BDRE Web Crawling\" width=\"240\" height=\"180\" border=\"10\" /></a>\r\n\r\n\r\n# Operational Metadata Management System\r\n\r\n### Operational Metadata Management\r\n\r\nBDRE provides complete job/operational metadata management solution for Hadoop. At its core acts as a registry and tracker for different types of jobs running in different Hadoop clusters or as a standalone. It provides APIs to integrate with virtually any jobs.\r\n\r\n\r\n![image](http://wiproopensourcepractice.github.io/openbdre/bdreimages/mdgraph.png)\r\n\r\n\r\nBDRE uses RDBMS database to store all job related metadata. A set of stored procedures are there to interface will the tables which are exposed via Java APIs to manage/create/update the static and run time metadata information. Below is the data model for BDRE metadata operational database.\r\n\r\n![eer](http://wiproopensourcepractice.github.io/openbdre/bdreimages/eer.png)\r\n\r\n# How to Contribute\r\n\r\nContribution for the enhancements in BDRE are welcome and humbly requested by us. To contribute, please navigate to our GitHub project page and [fork](https://help.github.com/articles/fork-a-repo/) BDRE main repository under your own account. You can make changes to your own forked repository and then open a [Pull Request](https://help.github.com/articles/creating-a-pull-request) to merge your change with the main repo.\r\n\r\n<a class=\"buttons github\" href=\"https://github.com/WiproOpenSourcePractice/openbdre\">Goto BDRE@GitHub</a>\r\n\r\n - Clone the main repo (if you havn't done already)\r\n \r\n```shell\r\ngit clone \"https://github.com/WiproOpenSourcePractice/openbdre.git\" \r\ncd openbdre\r\n```\r\n\r\n - Add your forked repo where you have write access and create your own branch.\r\n \r\n```shell\r\ngit remote add myrepo https://<your id>:<your password>@github.com/<YOUR ACCT NAME>/openbdre.git\r\ngit checkout -b mybranch\r\n```\r\n\r\n - Make and commit your changes to your own branch.\r\n \r\n```shell\r\ngit commit -am \"My changes\"\r\n```\r\n\r\n - Push to your own branch in your own remote repo (myrepo).\r\n \r\n```shell\r\ngit push myrepo mybranch\r\n```\r\n\r\n - Everyday better pull from the main repo(origin) and sync your repo with it.\r\n \r\n```shell\r\ngit checkout develop\r\ngit pull origin develop \r\n```\r\n\r\n - Keep the develop branch only to have the latest main repo content. Make changes while you are in your own branch.\r\n\r\n - Sync your code with the main repo. Push the latest content pulled from the main repo to your own repo in your own branch.\r\n\r\n```shell\r\ngit checkout mybranch \r\ngit merge develop\r\ngit push myrepo mybranch\r\n```\r\n\r\n - When you are ready to submit your contribution to the main repo, please open a [pull request](https://help.github.com/articles/creating-a-pull-request).\r\n - Please join the community https://groups.google.com/forum/#!forum/bdre. If you have any questions/suggestions please email to bdre-queries@googlegroups.com .\r\n - If you want to report a bug, see/request a feature or work on something. Please sign up at https://openbdre.atlassian.net\r\n \r\n","google":"UA-72345517-1","note":"Don't delete this file! It's used internally to help with page regeneration."}